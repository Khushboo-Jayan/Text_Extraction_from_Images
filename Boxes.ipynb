{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "def draw_boxes_on_character(img_path):\n",
    "    # Load the image using OpenCV\n",
    "    img = cv2.imread(img_path)\n",
    "    img= cv2.resize(img,(500,800))\n",
    "    img_height, img_width, _ = img.shape  # Get image dimensions\n",
    "\n",
    "    # Use Tesseract to get character-level bounding box information\n",
    "    boxes = pytesseract.image_to_boxes(img)\n",
    "\n",
    "    for box in boxes.splitlines():\n",
    "        box = box.split(\" \")\n",
    "        character = box[0]\n",
    "        x = int(box[1])\n",
    "        y = int(box[2])\n",
    "        x2 = int(box[3])\n",
    "        y2 = int(box[4])\n",
    "\n",
    "        # Draw a bounding box around the character\n",
    "        cv2.rectangle(img, (x, img_height - y), (x2, img_height - y2), (0, 255, 0), 1)\n",
    "\n",
    "        # Add the character as a label\n",
    "        cv2.putText(img, character, (x, img_height - y2), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 1)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Specify the path to the image you want to process\n",
    "input_image_path = 'Boss.jpeg'\n",
    "\n",
    "# Call the function to draw boxes on detected characters\n",
    "result_image = draw_boxes_on_character(input_image_path)\n",
    "\n",
    "# Display or save the resulting image\n",
    "cv2.imshow('Detected Characters', result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# If you want to save the result to a file, you can use cv2.imwrite()\n",
    "# cv2.imwrite('result_image.jpg', result_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hep guys wetcom 1 my\n",
      "\n",
      "channel\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "def print_detected_characters(img_path):\n",
    "    # Load the image using OpenCV\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (500, 800))\n",
    "\n",
    "    # Use Tesseract to get character-level information\n",
    "    characters = pytesseract.image_to_string(img)\n",
    "\n",
    "    # Print the detected characters\n",
    "    print(characters)\n",
    "\n",
    "# Specify the path to the image you want to process\n",
    "input_image_path = 'Boss.jpeg'\n",
    "\n",
    "# Call the function to print the detected characters\n",
    "print_detected_characters(input_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "def draw_boxes_on_text(img_path):\n",
    "    # Load the image using OpenCV\n",
    "    img = cv2.imread(img_path)\n",
    "    img= cv2.resize(img,(500,800))\n",
    "\n",
    "    # Return raw information about the detected texts\n",
    "    raw_data = pytesseract.image_to_data(img)\n",
    "\n",
    "    for count, data in enumerate(raw_data.splitlines()):\n",
    "        if count > 0:\n",
    "            data = data.split()\n",
    "            if len(data) == 12:\n",
    "                x, y, w, h, content = int(data[6]), int(data[7]), int(data[8]), int(data[9]), data[11]\n",
    "                \n",
    "                # Draw a bounding box around the detected text\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "                \n",
    "                # Add the detected text as a label\n",
    "                cv2.putText(img, content, (x, y - 10), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Specify the path to the image you want to process\n",
    "input_image_path = 'Boss.jpeg'\n",
    "\n",
    "# Call the function to draw boxes on detected text\n",
    "result_image = draw_boxes_on_text(input_image_path)\n",
    "\n",
    "# Display or save the resulting image\n",
    "cv2.imshow('Detected Text', result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# If you want to save the result to a file, you can use cv2.imwrite()\n",
    "# cv2.imwrite('result_image.jpg', result_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array split does not result in an equal division",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8c6e161f1779>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Divide the image into 5000 small dimensions of size 20x20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdivisions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Convert into Numpy array of size (50, 100, 20, 20)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mvsplit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mvsplit\u001b[1;34m(ary, indices_or_sections)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vsplit only works on arrays of 2 or more dimensions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_or_sections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msections\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    873\u001b[0m                 'array split does not result in an equal division') from None\n\u001b[0;32m    874\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_or_sections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array split does not result in an equal division"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread('Boss.jpeg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Divide the image into 5000 small dimensions of size 20x20\n",
    "divisions = list(np.hsplit(i, 100) for i in np.vsplit(gray_img, 50))\n",
    "\n",
    "# Convert into Numpy array of size (50, 100, 20, 20)\n",
    "NP_array = np.array(divisions)\n",
    "\n",
    "# Preparing train_data and test_data\n",
    "# Size will be (2500, 20x20)\n",
    "train_data = NP_array[:, :50].reshape(-1, 400).astype(np.float32)\n",
    "\n",
    "# Size will be (2500, 20x20)\n",
    "test_data = NP_array[:, 50:100].reshape(-1, 400).astype(np.float32)\n",
    "\n",
    "# Create 10 different labels for each type of digit\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250)[:, np.newaxis]\n",
    "test_labels = np.repeat(k, 250)[:, np.newaxis]\n",
    "\n",
    "# Initiate k-NN classifier\n",
    "knn = cv2.ml.KNearest_create()\n",
    "\n",
    "# Perform training of data\n",
    "knn.train(train_data, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "# Obtain the output from the classifier by specifying the number of neighbors.\n",
    "ret, output, neighbours, distance = knn.findNearest(test_data, k=3)\n",
    "\n",
    "# Check the performance and accuracy of the classifier.\n",
    "# Compare the output with test_labels to find out how many are wrong.\n",
    "matched = output == test_labels\n",
    "correct_OP = np.count_nonzero(matched)\n",
    "\n",
    "# Calculate the accuracy.\n",
    "accuracy = (correct_OP * 100.0) / output.size\n",
    "\n",
    "# Display accuracy.\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"tensorflow<2.11\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
